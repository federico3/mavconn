/*=====================================================================

PIXHAWK Micro Air Vehicle Flying Robotics Toolkit

(c) 2009, 2010 PIXHAWK PROJECT  <http://pixhawk.ethz.ch>

This file is part of the PIXHAWK project

    PIXHAWK is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    PIXHAWK is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with PIXHAWK. If not, see <http://www.gnu.org/licenses/>.

======================================================================*/

/**
 * @file
 *   @brief Implementation of the class PxCameraStereoCalibration.
 *
 *   @author Petri Tanskanen <mavteam@student.ethz.ch>
 *
 */

#include <iostream>
#include <iomanip>
#include <fstream>
#include <string>

#include <opencv2/calib3d/calib3d.hpp>
#include <opencv2/imgproc/imgproc.hpp>

#include "PxCameraStereoCalibration.h"

using namespace std;

/**
 * @param filename		Path to the calibration file
 * @param frameSize     Size of the image
 */
PxCameraStereoCalibration::PxCameraStereoCalibration(const char *filename, const cv::Size &frameSize)
: m_calibL(NULL), m_calibR(NULL), m_frameSize(frameSize)
{
	// Load the calibration file
    ifstream calfile;
    calfile.open(filename, ifstream::in);
    if (!calfile) {
    	perror("Unable to open file");
        //cout << "Unable to open file\n";
        exit(1); // terminate with error
    }

    // read the filename of the left camera calibration file
    string fileCalibL;
    getline(calfile,fileCalibL);
    m_calibL = new PxCameraCalibrationStandard(fileCalibL.c_str());

    // read the filename of the right camera calibration file
	string fileCalibR;
	getline(calfile,fileCalibR);
	m_calibR = new PxCameraCalibrationStandard(fileCalibR.c_str());

    // Process the values
	for (int i = 0; i < 3; ++i)
	{
		calfile >> m_rotation.at<double>(i,0); // rotation
	}
	for (int i = 0; i < 3; ++i)
	{
		calfile >> m_translation.at<double>(i,0); // translation
	}

    // Close the calibration file
    calfile.close();

    // now create the rectifying undistortion maps
    cv::Mat R1, R2, P1, P2;
    cv::Mat rotationMat;
    cv::Rodrigues(m_rotation, rotationMat);

	cv::stereoRectify(m_calibL->getIntrinsicMatrix(), m_calibL->distortion(),
					  m_calibR->getIntrinsicMatrix(), m_calibR->distortion(),
				      frameSize, rotationMat, m_translation,
				      R1, R2, P1, P2, m_Q, CV_CALIB_ZERO_DISPARITY,
                      -1, cv::Size(), &leftRectROI);

	cv::initUndistortRectifyMap(m_calibL->getIntrinsicMatrix(), m_calibL->distortion(), R1, P1, frameSize, CV_32FC1, m_mapxL, m_mapyL);
	cv::initUndistortRectifyMap(m_calibR->getIntrinsicMatrix(), m_calibR->distortion(), R2, P2, frameSize, CV_32FC1, m_mapxR, m_mapyR);

	// create the rectifying transformations (Px * Rx) - this is for undistortion of points
//	double PP[3][3];
//	double tmp[3][3];
//	CvMat _P3x3, _PP=cvMat(3, 3, CV_64F, PP);
//	CvMat _tmp=cvMat(3, 3, CV_64F, tmp);
//	cvConvert( cvGetCols(&P1, &_P3x3, 0, 3), &_PP );
//	cvMatMul( &_PP, &R1, &_tmp );
//	cvConvert(&_tmp, &m_RectTransformL);
//	cvConvert( cvGetCols(&P2, &_P3x3, 0, 3), &_PP );
//	cvMatMul( &_PP, &R2, &_tmp );
//	cvConvert(&_tmp, &m_RectTransformR);
	cv::Mat tmp1 = cv::Mat(P1(cv::Range(0,2), cv::Range(0,2)).mul(R1));
	m_RectTransformL[0] = tmp1.at<float>(0,0); m_RectTransformL[1] = tmp1.at<float>(0,1); m_RectTransformL[2] = tmp1.at<float>(0,2);
	m_RectTransformL[3] = tmp1.at<float>(1,0); m_RectTransformL[4] = tmp1.at<float>(1,1); m_RectTransformL[5] = tmp1.at<float>(1,2);
	m_RectTransformL[6] = tmp1.at<float>(2,0); m_RectTransformL[7] = tmp1.at<float>(2,1); m_RectTransformL[8] = tmp1.at<float>(2,2);

	tmp1 = cv::Mat(P2(cv::Range(0,2), cv::Range(0,2)).mul(R2));
	m_RectTransformR[0] = tmp1.at<float>(0,0); m_RectTransformR[1] = tmp1.at<float>(0,1); m_RectTransformR[2] = tmp1.at<float>(0,2);
	m_RectTransformR[3] = tmp1.at<float>(1,0); m_RectTransformR[4] = tmp1.at<float>(1,1); m_RectTransformR[5] = tmp1.at<float>(1,2);
	m_RectTransformR[6] = tmp1.at<float>(2,0); m_RectTransformR[7] = tmp1.at<float>(2,1); m_RectTransformR[8] = tmp1.at<float>(2,2);

	// create the new float intrinsic matrices
	m_intrisicMatrixL[0] = P1.at<float>(0,0); m_intrisicMatrixL[1] = 0.f;               m_intrisicMatrixL[2] = P1.at<float>(0,2);
	m_intrisicMatrixL[3] = 0.f;               m_intrisicMatrixL[4] = P1.at<float>(1,1); m_intrisicMatrixL[5] = P1.at<float>(1,2);
	m_intrisicMatrixL[6] = 0.f;               m_intrisicMatrixL[7] = 0.f;               m_intrisicMatrixL[8] = 1.f;

	m_intrisicMatrixR[0] = P2.at<float>(0,0); m_intrisicMatrixR[1] = 0.f;               m_intrisicMatrixR[2] = P2.at<float>(0,2);
	m_intrisicMatrixR[3] = 0.f;               m_intrisicMatrixR[4] = P2.at<float>(1,1); m_intrisicMatrixR[5] = P2.at<float>(1,2);
	m_intrisicMatrixR[6] = 0.f;               m_intrisicMatrixR[7] = 0.f;               m_intrisicMatrixR[8] = 1.f;

	m_intrisicMatrixInverseL[0] = 1.f/P1.at<float>(0,0); m_intrisicMatrixInverseL[1] = 0.0f;                    m_intrisicMatrixInverseL[2] = -P1.at<float>(0,2)/P1.at<float>(0,0);
	m_intrisicMatrixInverseL[3] = 0.0f;                    m_intrisicMatrixInverseL[4] = 1.f/P1.at<float>(1,1); m_intrisicMatrixInverseL[5] = -P1.at<float>(1,2)/P1.at<float>(1,1);
	m_intrisicMatrixInverseL[6] = 0.0f;                    m_intrisicMatrixInverseL[7] = 0.0f;                    m_intrisicMatrixInverseL[8] = 1.f;

	m_intrisicMatrixInverseR[0] = 1.f/P2.at<float>(0,0); m_intrisicMatrixInverseR[1] = 0.0f;                    m_intrisicMatrixInverseR[2] = -P2.at<float>(0,2)/P2.at<float>(0,0);
	m_intrisicMatrixInverseR[3] = 0.0f;                    m_intrisicMatrixInverseR[4] = 1.f/P2.at<float>(1,1); m_intrisicMatrixInverseR[5] = -P2.at<float>(1,2)/P2.at<float>(1,1);
	m_intrisicMatrixInverseR[6] = 0.0f;                    m_intrisicMatrixInverseR[7] = 0.0f;                    m_intrisicMatrixInverseR[8] = 1.f;
}

PxCameraStereoCalibration::~PxCameraStereoCalibration(void)
{
	if (m_calibL) delete m_calibL;
	if (m_calibR) delete m_calibR;
}

/**
* \param pSrc		An array of distorted image points (or pointer to a single CvPoint2D32f if only one point should be undistorted, use with count=1)
* \param pDest		An array where the undistorted image points are written into, can be equal to _src
* \param count		Number of the input and output points
*
* Computes the undistorted image coordinates of all the input points in the left image.
*
* All matrices, scalars and maps have to be floats!
*/
void PxCameraStereoCalibration::undistortPointsLeft(const CvPoint2D32f *pSrc, CvPoint2D32f *pDest, int count) const
{
	const int iters = 5;
	const float ifx = 1.f / m_calibL->focalLength()[0]; // 1.f / focal_x;
	const float ify = 1.f / m_calibL->focalLength()[1]; // 1.f / focal_y;
	const float cx = m_calibL->principalPoint()[0];
	const float cy = m_calibL->principalPoint()[1];
	const std::vector<float>& m_kc = m_calibL->distortionCoeffs();

	for(int i = 0; i < count; i++ )
	{
		float x = pSrc[i].x;
		float y = pSrc[i].y;

		float x0 = x = (x - cx)*ifx;
		float y0 = y = (y - cy)*ify;

		// compensate distortion iteratively
		for(int j = 0; j < iters; j++ )
		{
			float r2 = x*x + y*y;
			float icdist = 1.f/(1 + ((m_kc[4]*r2 + m_kc[1])*r2 + m_kc[0])*r2);
			float deltaX = 2*m_kc[2]*x*y + m_kc[3]*(r2 + 2*x*x);
			float deltaY = m_kc[2]*(r2 + 2*y*y) + 2*m_kc[3]*x*y;
			x = (x0 - deltaX)*icdist;
			y = (y0 - deltaY)*icdist;
		}

		float xx = m_RectTransformL[0]*x + m_RectTransformL[1]*y + m_RectTransformL[2];
		float yy = m_RectTransformL[3]*x + m_RectTransformL[4]*y + m_RectTransformL[5];
		float ww = 1.f/(m_RectTransformL[6]*x + m_RectTransformL[7]*y + m_RectTransformL[8]);

		pDest[i].x = xx*ww;
		pDest[i].y = yy*ww;
	}
}

/**
* \param pSrc		An array of distorted image points (or pointer to a single CvPoint2D32f if only one point should be undistorted, use with count=1)
* \param pDest		An array where the undistorted image points are written into, can be equal to _src
* \param count		Number of the input and output points
*
* Computes the undistorted image coordinates of all the input points in the right image.
*
* All matrices, scalars and maps have to be floats!
*/
void PxCameraStereoCalibration::undistortPointsRight(const CvPoint2D32f *pSrc, CvPoint2D32f *pDest, int count) const
{
	const int iters = 5;
	const float ifx = 1.f / m_calibR->focalLength()[0]; // 1.f / focal_x;
	const float ify = 1.f / m_calibR->focalLength()[1]; // 1.f / focal_y;
	const float cx = m_calibR->principalPoint()[0];
	const float cy = m_calibR->principalPoint()[1];
	const std::vector<float>& m_kc = m_calibR->distortionCoeffs();

	for(int i = 0; i < count; i++ )
	{
		float x = pSrc[i].x;
		float y = pSrc[i].y;

		float x0 = x = (x - cx)*ifx;
		float y0 = y = (y - cy)*ify;

		// compensate distortion iteratively
		for(int j = 0; j < iters; j++ )
		{
			float r2 = x*x + y*y;
			float icdist = 1.f/(1 + ((m_kc[4]*r2 + m_kc[1])*r2 + m_kc[0])*r2);
			float deltaX = 2*m_kc[2]*x*y + m_kc[3]*(r2 + 2*x*x);
			float deltaY = m_kc[2]*(r2 + 2*y*y) + 2*m_kc[3]*x*y;
			x = (x0 - deltaX)*icdist;
			y = (y0 - deltaY)*icdist;
		}

		float xx = m_RectTransformR[0]*x + m_RectTransformR[1]*y + m_RectTransformR[2];
		float yy = m_RectTransformR[3]*x + m_RectTransformR[4]*y + m_RectTransformR[5];
		float ww = 1.f/(m_RectTransformR[6]*x + m_RectTransformR[7]*y + m_RectTransformR[8]);

		pDest[i].x = xx*ww;
		pDest[i].y = yy*ww;
	}
}

/**
* @return	The calibration object of the left camera.
*/
const PxCameraCalibrationStandard &PxCameraStereoCalibration::getOriginalCalibrationLeft(void) const
{
	assert(m_calibL != NULL);
	return *m_calibL;
}

/**
* @return	The calibration object of the right camera.
*/
const PxCameraCalibrationStandard &PxCameraStereoCalibration::getOriginalCalibrationRight(void) const
{
	assert(m_calibR != NULL);
	return *m_calibR;
}

